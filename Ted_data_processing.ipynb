{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"name":"ted-data.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"cO9S_awaldSC","colab_type":"text"},"source":["This notebook does the preprocessing on the data that is common to all the models. This is just basic processing including removal of non-latin characters and splitting the data by label. This notebook was originally run in kaggle, where the source data is held, and produces the file 'ted_training_pairs_NLTK2.csv' found in the Drive."]},{"cell_type":"code","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","id":"hcsV2EISlbrp","colab_type":"code","colab":{}},"source":["# importing pandas module  \n","import pandas as pd \n","\n","# reading csv file from url  \n","data = pd.read_csv(\"/kaggle/input/ted-talks/transcripts.csv\")\n","   \n","# dropping null value columns to avoid errors \n","data.dropna(inplace = True) \n","  \n","# df display \n","data\n","\n","import re\n","import nltk"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nJvF5COnlbsC","colab_type":"code","colab":{},"outputId":"d9d10cdc-a853-4c0d-d120-d891d3e3e950"},"source":["print(len(data))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2467\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"p6L5eqvylbsZ","colab_type":"code","colab":{},"outputId":"3430422b-164e-4d6d-e23c-681cbb2d7ab1"},"source":["data.transcript.str.count(\"(Laughter)\").sum()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10251"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"N8_owGQOlbsv","colab_type":"code","colab":{}},"source":["import random\n","utterances = pd.DataFrame(columns=['talk','text','label'])\n","\n","for talk in range(len(data)):\n","    laughter_count = 0\n","    # Split by laughter\n","    laughter_split = data['transcript'][talk].split('(Laughter)')\n","    talk_neutrals = []\n","    # Ignore talks that did not have laughter (i.e. did not split)\n","    if len(laughter_split) > 1:\n","        for i, split in enumerate(laughter_split):\n","            # Ignore the final split as it is not followed by laughter\n","            if i < len(laughter_split) -1:\n","                # Split the text block that was followed by laughter into sentences\n","                sentences = nltk.sent_tokenize(laughter_split[i])\n","                if len(sentences) >= 2:\n","                    laughter_count += 1\n","                    # Take the sentence immediately preceding the laughter and add it to our training data\n","                    # Take all other sentences from this block and add to a neutral_sentences list\n","                    # There is sometimes applause and laughter together (Applause)(Laughter). \n","                    # For these cases we take the sentence preceding the applause and assume it also caused the laughter.\n","                    if sentences[-1] == \"(Applause)\":\n","                        laughter_utterance = sentences[-2]\n","                        neutral_utterances = sentences[:-2]\n","                        talk_neutrals += neutral_utterances\n","                        utterances = utterances.append({'talk':data['url'][talk], 'text': laughter_utterance, 'label': 'laughter'}, ignore_index=True)\n","                    else:\n","                        laughter_utterance = sentences[-1]\n","                        neutral_utterances = sentences[:-1]\n","                        talk_neutrals += neutral_utterances\n","                        utterances = utterances.append({'talk':data['url'][talk], 'text': laughter_utterance, 'label': 'laughter'}, ignore_index=True)\n","                # If the text block prior to laughter only has two sentences, we don't apply the (applause)(sentence) logic\n","                elif len(sentences) == 2:\n","                    laughter_count += 1\n","                    laughter_utterance = sentences[-1]\n","                    neutral_utterance = sentences[:-1]\n","                    talk_neutrals += neutral_utterances\n","                    utterances = utterances.append({'talk':data['url'][talk], 'text': laughter_utterance, 'label': 'laughter'}, ignore_index=True)\n","        # If there is at least one neutral sentence in the talk, take a random sample of the neutral sentences. N = no. of laughter sentences.\n","        # Random sample is without replacement if there are sufficient neutral sentences in the talk, with replacement otherwise.\n","        #if len(talk_neutrals) > 0:\n","        if laughter_count > len(talk_neutrals):\n","            random_neutral = random.sample(talk_neutrals, laughter_count)\n","        else:\n","            random_neutral = random.choices(talk_neutrals, k=laughter_count)\n","        for neutral in random_neutral:\n","            utterances = utterances.append({'talk':data['url'][talk], 'text': neutral, 'label': 'neutral'}, ignore_index=True)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NVpHbhDIlbtE","colab_type":"code","colab":{}},"source":["# Add spaces between punctuation\n","for i in range(len(utterances)):\n","    utterances['text'][i] = re.sub('([.,!?()])', r' \\1 ', utterances['text'][i])\n","    utterances['text'][i] = re.sub('\\s{2,}', ' ', utterances['text'][i])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JQJWyOzvlbtY","colab_type":"code","colab":{},"outputId":"b625d689-7fb2-4a70-fa88-7747ce72a292"},"source":["# Identify duplicate neutral utterances caused by sampling with replacement where there are insufficient neutral sentences in a talk\n","duplicaterows = utterances[utterances.duplicated()]\n","print(duplicaterows)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["                                                    talk  \\\n","38     https://www.ted.com/talks/ken_robinson_says_sc...   \n","111    https://www.ted.com/talks/david_pogue_says_sim...   \n","118    https://www.ted.com/talks/david_pogue_says_sim...   \n","121    https://www.ted.com/talks/david_pogue_says_sim...   \n","229    https://www.ted.com/talks/julia_sweeney_on_let...   \n","...                                                  ...   \n","17258  https://www.ted.com/talks/david_whyte_a_lyrica...   \n","17283  https://www.ted.com/talks/laolu_senbanjo_the_s...   \n","17421  https://www.ted.com/talks/jun_wang_how_digital...   \n","17455  https://www.ted.com/talks/theo_e_j_wilson_a_bl...   \n","17464  https://www.ted.com/talks/theo_e_j_wilson_a_bl...   \n","\n","                                                    text    label  \n","38     If you look at the interactions of a human bra...  neutral  \n","111                             It's in your gift bag .   neutral  \n","118    You might've seen this , this is Apple's new l...  neutral  \n","121    Every software company is doing Microsoft's R&...  neutral  \n","229                        What does that mean again ? \"  neutral  \n","...                                                  ...      ...  \n","17258  So really , this first ritual is saying: How d...  neutral  \n","17283  Every artist has a name , and every artist has...  neutral  \n","17421  And what kind of decision is the right one to ...  neutral  \n","17455  I mean , America seems to be hellbent on filli...  neutral  \n","17464  See , being a survivor myself of police brutal...  neutral  \n","\n","[388 rows x 3 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YlcgvTYTlbtu","colab_type":"code","colab":{},"outputId":"aced1acd-cff1-4cef-c3ac-8329946c6e03"},"source":["utterances.groupby('label').count()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>talk</th>\n","      <th>text</th>\n","    </tr>\n","    <tr>\n","      <th>label</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>laughter</th>\n","      <td>8733</td>\n","      <td>8733</td>\n","    </tr>\n","    <tr>\n","      <th>neutral</th>\n","      <td>8733</td>\n","      <td>8733</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          talk  text\n","label               \n","laughter  8733  8733\n","neutral   8733  8733"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"pGFepI_Plbt_","colab_type":"code","colab":{},"outputId":"9afe7e67-223b-4d08-a36f-60f7c1e83574"},"source":["summary = utterances.groupby('talk').count()\n","print(summary)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["                                                    text  label\n","talk                                                           \n","https://www.ted.com/talks/9_11_healing_the_moth...     2      2\n","https://www.ted.com/talks/a_j_jacobs_year_of_li...    22     22\n","https://www.ted.com/talks/a_robot_that_flies_li...     4      4\n","https://www.ted.com/talks/a_ted_speaker_s_worst...     2      2\n","https://www.ted.com/talks/a_whistleblower_you_h...    22     22\n","...                                                  ...    ...\n","https://www.ted.com/talks/zeresenay_alemseged_l...     8      8\n","https://www.ted.com/talks/zeynep_tufekci_how_th...     2      2\n","https://www.ted.com/talks/zeynep_tufekci_machin...    14     14\n","https://www.ted.com/talks/zimchallenge\\n               6      6\n","https://www.ted.com/talks/zubaida_bai_a_simple_...     2      2\n","\n","[1802 rows x 2 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3S-OErjblbuR","colab_type":"code","colab":{}},"source":["utterances.to_csv('ted_training_pairs_NLTK2.csv',index=False)"],"execution_count":0,"outputs":[]}]}