{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Group_16_Logistic_Regression.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"oEAQhbR9jJML","colab_type":"text"},"source":["This Notebook trains and evaluates (with CV) a Bag-of-words TF-IDF logistic regression model.\n","\n","Group:16"]},{"cell_type":"code","metadata":{"id":"NodAQD98PQKt","colab_type":"code","colab":{}},"source":["import sys\n","import time\n","import os\n","import math\n","import copy\n","import string\n","import re\n","from IPython.display import clear_output\n","import nltk\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from textblob import TextBlob\n","import torch\n","import torch.nn as nn\n","import torch.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader, Subset, ConcatDataset, TensorDataset\n","from torch.autograd import Variable\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","from torchvision.utils import save_image\n","\n","import gensim\n","from gensim.models import Word2Vec\n","from gensim.models import KeyedVectors\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"py9SjcroPQKx","colab_type":"code","colab":{}},"source":["# utilising the gpu\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JblO-LA3PZEY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":17},"outputId":"a08da132-9112-45de-a401-8c1663329885"},"source":["%%shell\n","curl -fsS https://nlp.stanford.edu/sentiment/trainDevTestTrees_PTB.zip -o /tmp/trainDevTestTrees_PTB.zip\n","unzip -q -o -d /tmp /tmp/trainDevTestTrees_PTB.zip\n","rm -f /tmp/trainDevTestTrees_PTB.zip"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":[""]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"iYQEFLsj3Xd6","colab_type":"text"},"source":["### Cleaning the Sentences"]},{"cell_type":"markdown","metadata":{"id":"BMNN8pg3PQK4","colab_type":"text"},"source":["Split data into sentences and labels"]},{"cell_type":"code","metadata":{"id":"jfR3YLYsj6Nm","colab_type":"code","colab":{}},"source":["from google.colab import drive, files\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z39j3lOxPQK4","colab_type":"code","colab":{}},"source":["filepath = \"gdrive/My Drive/ted_training_pairs_NLTK2.csv\"\n","# read in data\n","data = pd.read_csv(filepath)\n","# split into data, labels\n","sentences = data['text'].values\n","labels = data['label'].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_cPucRfGPQK_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"outputId":"4b97f6cc-4488-4395-db63-a9abb25d70d1"},"source":["labels[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'laughter'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"YM1MwPErPQLD","colab_type":"text"},"source":["Remove punctuation from each sentence"]},{"cell_type":"code","metadata":{"id":"DCPiAZUTPQLD","colab_type":"code","colab":{}},"source":["#Create list of all punctuation in the text\n","punctuation = []\n","for p in string.punctuation:\n","    punctuation.append(p)\n","punctuation.append(\"''\")\n","punctuation.append(\"--\")\n","punctuation.append(\"##\")\n","punctuation.append(\"``\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jkMAapVdPQLH","colab_type":"code","colab":{}},"source":["new_sentences = []\n","for sentence in sentences:\n","    words = sentence.split()\n","    no_punc_words = [words[i] for i in range(len(words)) if words[i] not in punctuation]\n","    new_sentences.append(\" \".join(no_punc_words))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AD5l6l79UW_h","colab_type":"code","colab":{}},"source":["from collections import Counter\n","\n","all_text = ' '.join(new_sentences)\n","words = all_text.split()\n","\n","# Count all the words using Counter Method\n","count_words = Counter(words)\n","\n","total_words = len(words)\n","sorted_words = count_words.most_common(total_words)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QBEuTVxgzls6","colab_type":"text"},"source":["This is where we start with BoW/ TfIdf model"]},{"cell_type":"code","metadata":{"id":"cP292ZCVgT3a","colab_type":"code","colab":{}},"source":["# Only keep words that appear more than once\n","processed_corpus = [[token for token in text.split() if count_words[token] > 1] for text in new_sentences]\n","#pprint.pprint(processed_corpus)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AH-gC0h-egAI","colab_type":"code","colab":{}},"source":["from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n","# create model\n","vect_word = TfidfVectorizer(max_features=2000, lowercase=True, analyzer='word',\n","                        stop_words= 'english',ngram_range=(1,3),dtype=np.float32)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kAXNUwwVeoCz","colab_type":"code","colab":{}},"source":["tr_vect = vect_word.fit_transform(sentences) #apply model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X1sg_QPRfEB0","colab_type":"code","colab":{}},"source":["# transform to pytorch Tensor via sparse matrix\n","coo = tr_vect.tocoo()\n","values = coo.data\n","indices = np.vstack((coo.row, coo.col))\n","\n","i = torch.LongTensor(indices)\n","v = torch.FloatTensor(values)\n","shape = coo.shape\n","\n","encoded2  = torch.sparse.FloatTensor(i, v, torch.Size(shape)).to_dense()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iXD9ayV7jc06","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"08805ebd-938b-46dc-8bd0-278b3562cf8d"},"source":["encoded.size()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([17466, 2000])"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"N8OtL3uzPQLb","colab_type":"text"},"source":["Now we will tokenize the labels"]},{"cell_type":"code","metadata":{"id":"getvYrTYPQLc","colab_type":"code","colab":{}},"source":["from sklearn.preprocessing import LabelEncoder\n","\n","enc = LabelEncoder()\n","labels_enc = enc.fit_transform(labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yZ-_E3QXPQLf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"outputId":"796e883e-b13e-4244-d320-dee4f181e49b"},"source":["labels_enc[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"V9q-Q4Gmkuc2","colab":{}},"source":["indices = list(range(encoded2.shape[0]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i-HnZ1SsPQL6","colab_type":"text"},"source":["We will now design the Logistic Regression model"]},{"cell_type":"code","metadata":{"id":"SfVlQkn2z_MT","colab_type":"code","colab":{}},"source":["### Linear Model for TfIDf where embeddings are precomputed and are fed in as vectors so no need for embeddings layer in model\n","### note that a number of the inputs are not necessary. This is just for compatibility with other models.\n","class LR(nn.Module):\n","    def __init__(self, embedding_dim, n_filters, filter_sizes, output_dim, \n","                 dropout):\n","        \n","        super().__init__()\n","\n","        self.fc = nn.Linear(embedding_dim, output_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, text):\n","            \n","        return self.fc(text)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ix2aJBfQPQL-","colab_type":"text"},"source":["Function to train the model"]},{"cell_type":"code","metadata":{"id":"zH5Dcra8PQL-","colab_type":"code","colab":{}},"source":["from sklearn.metrics import roc_auc_score,f1_score,confusion_matrix\n","\n","def binary_accuracy(preds, y):\n","\n","    #round predictions to the closest integer\n","    probs = torch.sigmoid(preds)\n","    rounded_preds = torch.round(probs)\n","    correct = (rounded_preds == y).float() #convert into float for division \n","    acc = correct.sum() / len(correct)\n","    \n","    return acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j8R8W380PQMB","colab_type":"code","colab":{}},"source":["\n","\n","def train(model, iterator, optimizer, criterion):\n","    # model training function - performs one epoch\n","    epoch_loss = 0\n","    epoch_acc = 0\n","    epoch_f1 = 0\n","    epoch_auc = 0\n","    pred_probs = np.array([])\n","    preds      = np.array([])\n","    labs = np.array([])\n","    model.train()\n","    \n","    for text, labels in iterator:\n","        \n","        text, labels = text.to(device), labels.to(device)\n","        \n","        optimizer.zero_grad()\n","        # forward\n","        predictions = model(text).squeeze(1)\n","        # loss\n","        loss = criterion(predictions, labels)\n","        # accuracy\n","        acc = binary_accuracy(predictions, labels)\n","        # collect probabilities and predicitons\n","        pred_prob = torch.sigmoid(predictions)\n","        pred_probs = np.append(pred_probs, pred_prob.detach().cpu())\n","        pred = torch.round(pred_prob)\n","        preds = np.append(preds, pred.detach().cpu())\n","        labs = np.append(labs,labels.detach().cpu())\n","\n","        # backward\n","        loss.backward()\n","        # optimise\n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","\n","    #f1 \n","    f1 =  f1_score(labs,preds)\n","    #auc  \n","    auc = roc_auc_score(labs,pred_probs) \n","    # return metrics for epoch    \n","    return epoch_loss/len(iterator) , epoch_acc / len(iterator), f1, auc\n","\n","def evaluate(model, iterator, criterion):\n","    # evaluate of test data. same as train but without model updating\n","    epoch_loss = 0\n","    epoch_acc = 0\n","    epoch_f1 = 0\n","    epoch_auc = 0\n","    pred_probs = np.array([])\n","    preds      = np.array([])\n","    labs = np.array([])\n","    model.eval()\n","    \n","    with torch.no_grad():\n","    \n","        for text, labels in iterator:\n","            \n","            text, labels = text.to(device), labels.to(device)\n","\n","            predictions = model(text).squeeze(1)\n","            \n","            loss = criterion(predictions, labels)\n","            \n","            acc = binary_accuracy(predictions, labels)\n","\n","            pred_prob = torch.sigmoid(predictions)\n","            pred_probs = np.append(pred_probs, pred_prob.detach().cpu())\n","            pred = torch.round(pred_prob)\n","            preds = np.append(preds, pred.detach().cpu())\n","            labs = np.append(labs,labels.detach().cpu())\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","\n","    #f1\n","    f1 =  f1_score(labs,preds)\n","    #auc  \n","    auc = roc_auc_score(labs,pred_probs)    \n","    return epoch_loss/len(iterator) , epoch_acc / len(iterator), f1, auc, preds\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"91p81nVSPQMD","colab_type":"code","colab":{}},"source":["def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jMoS0voJPQMG","colab_type":"text"},"source":["Helper function to make plots of the loss and accuracy on the training set and validation set"]},{"cell_type":"code","metadata":{"id":"YYjzmzJmPQMH","colab_type":"code","colab":{}},"source":["def plot_loss_accuracy(train_loss, valid_loss, train_acc, valid_acc):\n","    #plots the loss and accuracy of training and validation set during training\n","    # comment out to suppress plot output\n","    fig = plt.figure(figsize=plt.figaspect(0.2))\n","    ax1 = fig.add_subplot(1,2,1)\n","    ax1.plot(train_loss, 'b')\n","    ax1.plot(valid_loss, 'r')\n","    plt.xlabel('epoch')\n","    plt.ylabel('Loss')\n","    ax1.legend(['Train', 'Validation'])  \n","    \n","    ax1 = fig.add_subplot(1,2,2)\n","    ax1.plot(train_acc, 'b')\n","    ax1.plot(valid_acc, 'r')\n","    plt.xlabel('epoch')\n","    plt.ylabel('Accuracy')\n","    ax1.legend(['Train', 'Validation'])\n","\n","    ltrain = np.array(train_loss)  \n","    least_train_epoch = np.argmin(ltrain)\n","    least_train_loss = min(train_loss)\n","    print('Lowest training loss:',least_train_loss,'achieved at epoch:',least_train_epoch)\n","    \n","    lval = np.array(valid_loss)  \n","    least_val_epoch = np.argmin(lval)\n","    least_val_loss = min(valid_loss)\n","    print('Lowest validation loss:',least_val_loss,'achieved at epoch:',least_val_epoch)\n","    \n","    atrain = np.array(train_acc)  \n","    best_train_epoch = np.argmax(atrain)\n","    best_train_accuracy = max(train_acc)\n","    print('Best training accuracy:',best_train_accuracy * 100,'achieved at epoch:',best_train_epoch)\n","    aval = np.array(valid_acc)  \n","    best_val_epoch = np.argmax(aval)\n","    best_val_accuracy = max(valid_acc)\n","    print('Best validation accuracy:',best_val_accuracy*100,'achieved at epoch:',best_val_epoch,'\\n')\n","    \n","    return least_train_loss, least_val_loss, best_train_accuracy, best_val_accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"50OaIH8FA0Wm","colab_type":"text"},"source":["Grid Search, Train and test"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"hL7WH8RlPQMP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"ebb75cec-b374-473f-9df6-a3ad3dc9b2b7"},"source":["EMBEDDING_DIM = encoded2.shape[1]\n","N_FILTERS = 100 #<- not applicable but necessary \n","N_FILTERS_list = [50, 100, 150] #<- not applicable but necessary \n","FILTER_SIZES = [3,4,5] #<- not applicable but necessary \n","FILTER_SIZES_list = [[3, 4, 5], [2, 3, 4]] #<- not applicable but necessary \n","OUTPUT_DIM = 1\n","DROPOUT_list = [0.3, 0.5, 0.7] #<- not applicable but necessary \n","DROPOUT = 0.5 #<- not applicable but necessary \n","\n","learning_rates = [0.0001, 0.001, 0.01]\n","batch_sizes = [25,50]\n","best_valid_loss = float('inf')\n","from sklearn.model_selection import StratifiedKFold\n","\n","# Here is where we implement the CV\n","\n","skf1 = StratifiedKFold(5)\n","\n","# averages over the test set\n","test_loss_avg = []\n","test_acc_avg = []\n","test_auc_avg = []\n","test_f1_avg = []\n","\n","\n","train_loss_avg = []\n","train_acc_avg = []\n","train_auc_avg = []\n","train_f1_avg = []\n","\n","conf_matrices = []\n","#  CV over 5 train test splits\n","for train_indices_m, test_indices in skf1.split(indices,labels_enc):\n","  \n","  \n","  \n","\n","  skf2 = StratifiedKFold(5)\n","  # averages over train and validation splits\n","  train_losses_avg = np.zeros((len(batch_sizes),len(learning_rates)))\n","  train_accs_avg = np.zeros((len(batch_sizes),len(learning_rates)))\n","  train_aucs_avg = np.zeros((len(batch_sizes),len(learning_rates)))\n","  train_f1s_avg = np.zeros((len(batch_sizes),len(learning_rates)))\n","\n","  train_losses_std = np.zeros((len(batch_sizes),len(learning_rates)))\n","  train_accs_std = np.zeros((len(batch_sizes),len(learning_rates)))\n","  train_aucs_std = np.zeros((len(batch_sizes),len(learning_rates)))\n","  train_f1s_std = np.zeros((len(batch_sizes),len(learning_rates)))\n","\n","\n","  val_losses_avg = np.zeros((len(batch_sizes),len(learning_rates)))\n","  val_accs_avg = np.zeros((len(batch_sizes),len(learning_rates)))\n","  val_aucs_avg = np.zeros((len(batch_sizes),len(learning_rates)))\n","  val_f1s_avg = np.zeros((len(batch_sizes),len(learning_rates)))\n","\n","  val_losses_std = np.zeros((len(batch_sizes),len(learning_rates)))\n","  val_accs_std = np.zeros((len(batch_sizes),len(learning_rates)))\n","  val_aucs_std = np.zeros((len(batch_sizes),len(learning_rates)))\n","  val_f1s_std = np.zeros((len(batch_sizes),len(learning_rates)))\n","\n","\n","  # grid search over params\n","  for i,batch_size in enumerate(batch_sizes):\n","\n","    for j,lr in enumerate(learning_rates):\n","      \n","      # losses will be averaged\n","      train_losses = []\n","      train_accs = []\n","      train_f1s = []\n","      train_aucs = []\n","\n","      val_losses = []\n","      val_accs = []\n","      val_f1s = []\n","      val_aucs = []\n","\n","      # CV for each parameter combination train split to train/ val\n","      for train_indices,val_indices in skf2.split(train_indices_m,labels_enc[train_indices_m]):\n","\n","\n","        # now split train and val\n","        X_train = encoded2[train_indices]\n","        y_train = labels_enc[train_indices]\n","\n","        X_val = encoded2[val_indices]\n","        y_val = labels_enc[val_indices]\n","\n","        # create Tensor datasets\n","        train_data = TensorDataset(X_train, torch.from_numpy(y_train).type(torch.FloatTensor))\n","        valid_data = TensorDataset(X_val, torch.from_numpy(y_val).type(torch.FloatTensor))\n","        \n","        # dataloaders\n","        \n","        # make sure to SHUFFLE your data\n","        train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last = False)\n","        valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size, drop_last = False)\n","        \n","        # instantiate model\n","        model = LR(EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT).to(device)\n","\n","        # loss function - using cross entropy loss\n","        criterion = nn.BCEWithLogitsLoss().to(device)\n","        optimizer = torch.optim.Adam(model.parameters(), lr= lr)\n","\n","        N_EPOCHS = 12\n","\n","        e_train_loss = np.inf\n","        e_train_acc = 0\n","        e_train_f1 = 0\n","        e_train_auc = 0\n","        \n","        e_valid_loss = np.inf\n","        e_valid_acc = 0\n","        e_valid_f1 = 0\n","        e_valid_auc = 0\n","\n","        for epoch in range(N_EPOCHS): # train for N epochs\n","\n","          start_time = time.time()\n","          \n","          train_loss, train_acc, train_f1, train_auc = train(model, train_loader, optimizer, criterion)\n","          valid_loss, valid_acc, valid_f1, valid_auc,_ = evaluate(model, valid_loader, criterion)\n","          # save best epoch metrics\n","          if valid_acc > e_valid_acc:\n","            e_train_loss = train_loss\n","            e_train_acc = train_acc\n","            e_train_f1 = train_f1\n","            e_train_auc = train_auc\n","            \n","            e_valid_loss = valid_loss\n","            e_valid_acc = valid_acc\n","            e_valid_f1 = valid_f1\n","            e_valid_auc = valid_auc\n","          \n","          \n","          end_time = time.time()\n","\n","          epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","        \n","          print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","          print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","          print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n","        clear_output(True)\n","        # save best epoch metrics for averaging\n","        train_losses.append(e_train_loss)\n","        train_accs.append(e_train_acc)\n","        train_f1s.append(e_train_f1)\n","        train_aucs.append(e_train_auc)\n","        \n","        val_losses.append(e_valid_loss)\n","        val_accs.append(e_valid_acc)\n","        val_f1s.append(e_valid_f1)\n","        val_aucs.append(e_valid_auc)\n","      # average best metrics for each parameter combination\n","      train_losses_avg[i,j] = np.array(train_losses).mean()\n","      train_accs_avg[i,j] = np.array(train_accs).mean()\n","      train_aucs_avg[i,j] = np.array(train_aucs).mean()\n","      train_f1s_avg[i,j] = np.array(train_f1s).mean()\n","\n","      train_losses_std[i,j] = np.array(train_losses).std()\n","      train_accs_std[i,j] = np.array(train_accs).std()\n","      train_aucs_std[i,j] = np.array(train_aucs).std()\n","      train_f1s_std[i,j] = np.array(train_f1s).std()\n","\n","\n","      val_losses_avg[i,j] = np.array(train_losses).mean()\n","      val_accs_avg[i,j] = np.array(train_accs).mean()\n","      val_aucs_avg[i,j] = np.array(train_aucs).mean()\n","      val_f1s_avg[i,j] = np.array(train_f1s).mean()\n","\n","      val_losses_std[i,j] = np.array(train_losses).std()\n","      val_accs_std[i,j] = np.array(train_accs).std()\n","      val_aucs_std[i,j] = np.array(train_aucs).std()\n","      val_f1s_std[i,j] = np.array(train_f1s).std()\n","\n","  # find best parameter combination\n","  i,j = np.unravel_index(np.argmin(val_losses_avg),val_losses_avg.shape)\n","  best_batch = batch_sizes[i]\n","  best_lr = learning_rates[j]\n","  # instantiate new model\n","  model = LR(EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT).to(device)\n","\n","  # loss function - using cross entropy loss\n","  criterion = nn.BCEWithLogitsLoss().to(device)\n","  optimizer = torch.optim.Adam(model.parameters(), lr= best_lr)\n","  # new train val split\n","  train_indices, valid_indices = train_test_split(train_indices_m, test_size = 0.2, shuffle = True)  \n","\n","  X_train = encoded2[train_indices]\n","  y_train = labels_enc[train_indices]\n","\n","  X_val = encoded2[valid_indices]\n","  y_val = labels_enc[valid_indices]\n","  # create test set here too\n","  X_test = encoded2[test_indices]\n","  y_test = labels_enc[test_indices]\n","\n","  train_data = TensorDataset(X_train, torch.from_numpy(y_test).type(torch.FloatTensor))\n","  valid_data = TensorDataset(X_val, torch.from_numpy(y_val).type(torch.FloatTensor))\n","  test_data = TensorDataset(X_test, torch.from_numpy(y_test).type(torch.FloatTensor))\n","\n","  train_loader = DataLoader(train_data, shuffle=True, batch_size=best_batch, drop_last = False)\n","  valid_loader = DataLoader(valid_data, shuffle=True, batch_size=best_batch, drop_last = False)\n","  test_loader = DataLoader(test_data, shuffle=False, batch_size=best_batch, drop_last = False)\n","\n","  N_EPOCHS = 12\n","\n","  e_train_loss = np.inf\n","  e_train_acc = 0\n","  e_train_f1 = 0\n","  e_train_auc = 0\n","  \n","  e_valid_loss = np.inf\n","  e_valid_acc = 0\n","  e_valid_f1 = 0\n","  e_valid_auc = 0\n","  # train\n","  for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","    \n","    train_loss, train_acc, train_f1, train_auc = train(model, train_loader, optimizer, criterion)\n","    valid_loss, valid_acc, valid_f1, valid_auc,_ = evaluate(model, valid_loader, criterion)\n","    \n","    \n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    if valid_loss < e_valid_loss:\n","      \n","      e_train_loss = train_loss\n","      e_train_acc = train_acc\n","      e_train_f1 = train_f1\n","      e_train_auc = train_auc\n","      \n","      e_valid_loss = valid_loss\n","      e_valid_acc = valid_acc\n","      e_valid_f1 = valid_f1\n","      e_valid_auc = valid_auc\n","      # save best model\n","      torch.save({'epoch': epoch,\n","                  'model_state_dict': model.state_dict(),\n","                  'optimizer_state_dict': optimizer.state_dict(),\n","                  'loss': e_valid_loss,\n","                  }, 'gridsearch-model.pt')\n","  \n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n","  # save metrics for averaging\n","  train_loss_avg.append(e_valid_loss)\n","  train_acc_avg.append(e_valid_acc)\n","  \n","  train_auc_avg.append(e_valid_f1)\n","  train_f1_avg.append(e_valid_auc)\n","\n","  # load best model back\n","  model = LR(EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT).to(device)\n","\n","  best_checkpoint = torch.load('gridsearch-model.pt')\n","  model.load_state_dict(best_checkpoint['model_state_dict'])\n","  optimizer.load_state_dict(best_checkpoint['optimizer_state_dict'])\n","  epoch = best_checkpoint['epoch']\n","  loss = best_checkpoint['loss']\n","\n","  print(model, optimizer)\n","  print(\"Best Epoch {}, Best Validation Loss {}\".format(epoch, loss))\n","  # evaluate on the test set\n","  print(\"Evaluating...\")\n","  test_loss, test_acc, test_f1, test_auc, preds  = evaluate(model, test_loader, criterion)\n","  print(f'\\tTest Loss: {test_loss:.3f} | Train Acc: {test_acc*100:.2f}%')\n","  print(\"Evaluation is Complete!\")\n","  # save test metrics for averaging\n","  test_loss_avg.append(test_loss)\n","  test_acc_avg.append(test_acc)\n","  \n","  test_auc_avg.append(test_f1)\n","  test_f1_avg.append(test_auc)\n","\n","  eval_confusion_matrix = confusion_matrix(test_loader.dataset.tensors[1], preds)\n","  conf_matrices.append(eval_confusion_matrix)\n","# display averaged train and test metrics\n","print('.....')\n","print(f'\\tMean Train Loss: {np.array(train_loss_avg).mean():.3f} |Std Train Loss: {np.array(train_loss_avg).std():.3f}')\n","print(f'\\tMean Train Acc: {np.array(train_acc_avg).mean()*100:.2f}% | Std Train Acc: {np.array(train_acc_avg).std():.3f}')\n","print(f'\\tMean Train F1: {np.array(train_f1_avg).mean():.3f} | Std Train F1: {np.array(train_f1_avg).std():.3f}')\n","print(f'\\tMean Train AUC: {np.array(train_auc_avg).mean():.3f} | Std Train AUC: {np.array(train_auc_avg).std():.3f}')\n","print('.....')\n","print(f'\\tMean Test Loss: {np.array(test_loss_avg).mean():.3f} |Std Test Loss: {np.array(test_loss_avg).std():.3f}')\n","print(f'\\tMean Test Acc: {np.array(test_acc_avg).mean()*100:.2f}% | Std Train Acc: {np.array(test_acc_avg).std():.3f}')\n","print(f'\\tMean Test F1: {np.array(test_f1_avg).mean():.3f} | Std Test F1: {np.array(test_f1_avg).std():.3f}')\n","print(f'\\tMean Test AUC: {np.array(test_auc_avg).mean():.3f} | Std Test AUC: {np.array(test_auc_avg).std():.3f}')\n","print(\"Evaluation is Complete!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch: 01 | Epoch Time: 0m 0s\n","\tTrain Loss: 0.692 | Train Acc: 52.50%\n","\t Val. Loss: 0.689 |  Val. Acc: 60.52%\n","Epoch: 02 | Epoch Time: 0m 0s\n","\tTrain Loss: 0.688 | Train Acc: 62.08%\n","\t Val. Loss: 0.685 |  Val. Acc: 63.33%\n","Epoch: 03 | Epoch Time: 0m 0s\n","\tTrain Loss: 0.683 | Train Acc: 64.64%\n","\t Val. Loss: 0.681 |  Val. Acc: 63.98%\n","Epoch: 04 | Epoch Time: 0m 0s\n","\tTrain Loss: 0.679 | Train Acc: 65.62%\n","\t Val. Loss: 0.678 |  Val. Acc: 64.37%\n","Epoch: 05 | Epoch Time: 0m 0s\n","\tTrain Loss: 0.676 | Train Acc: 65.95%\n","\t Val. Loss: 0.675 |  Val. Acc: 65.06%\n","Epoch: 06 | Epoch Time: 0m 0s\n","\tTrain Loss: 0.672 | Train Acc: 66.35%\n","\t Val. Loss: 0.672 |  Val. Acc: 65.78%\n","Epoch: 07 | Epoch Time: 0m 0s\n","\tTrain Loss: 0.668 | Train Acc: 66.40%\n","\t Val. Loss: 0.669 |  Val. Acc: 66.04%\n","Epoch: 08 | Epoch Time: 0m 0s\n","\tTrain Loss: 0.665 | Train Acc: 67.29%\n","\t Val. Loss: 0.666 |  Val. Acc: 65.11%\n","Epoch: 09 | Epoch Time: 0m 0s\n","\tTrain Loss: 0.662 | Train Acc: 66.75%\n","\t Val. Loss: 0.663 |  Val. Acc: 65.31%\n","Epoch: 10 | Epoch Time: 0m 0s\n","\tTrain Loss: 0.659 | Train Acc: 66.66%\n","\t Val. Loss: 0.660 |  Val. Acc: 66.29%\n","Epoch: 11 | Epoch Time: 0m 0s\n","\tTrain Loss: 0.656 | Train Acc: 67.53%\n","\t Val. Loss: 0.658 |  Val. Acc: 65.31%\n","Epoch: 12 | Epoch Time: 0m 0s\n","\tTrain Loss: 0.653 | Train Acc: 66.72%\n","\t Val. Loss: 0.656 |  Val. Acc: 66.33%\n","LR(\n","  (fc): Linear(in_features=2000, out_features=1, bias=True)\n","  (dropout): Dropout(p=0.5, inplace=False)\n",") Adam (\n","Parameter Group 0\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    eps: 1e-08\n","    lr: 0.001\n","    weight_decay: 0\n",")\n","Best Epoch 11, Best Validation Loss 0.6557635728801999\n","Evaluating...\n","\tTest Loss: 0.679 | Train Acc: 57.95%\n","Evaluation is Complete!\n",".....\n","\tMean Train Loss: 0.635 |Std Train Loss: 0.012\n","\tMean Train Acc: 65.16% | Std Train Acc: 0.012\n","\tMean Train F1: 0.703 | Std Train F1: 0.012\n","\tMean Train AUC: 0.633 | Std Train AUC: 0.014\n",".....\n","\tMean Test Loss: 0.621 |Std Test Loss: 0.048\n","\tMean Test Acc: 65.49% | Std Train Acc: 0.056\n","\tMean Test F1: 0.711 | Std Test F1: 0.075\n","\tMean Test AUC: 0.641 | Std Test AUC: 0.052\n","Evaluation is Complete!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IUMyjqXjgkqq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":528},"outputId":"e5dec57f-e8f3-4f18-8335-170ef86be6ae"},"source":["# confusion matrix\n","mean_confusions = np.mean(np.array(conf_matrices), axis = 0)\n","std_confusions = np.std(np.array(conf_matrices), axis = 0)\n","\n","label_names = [\"Laughter\", \"Neutral\"]\n","\n","fig, ax = plt.subplots(figsize = (8, 8))\n","im = ax.imshow(mean_confusions, cmap = \"Blues\")\n","\n","# We want to show all ticks...\n","ax.set_xticks(np.arange(len(label_names)))\n","ax.set_yticks(np.arange(len(label_names)))\n","# ... and label them with the respective list entries\n","ax.set_xticklabels(label_names)\n","ax.set_yticklabels(label_names)\n","\n","# Rotate the tick labels and set their alignment.\n","plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n","         rotation_mode=\"anchor\")\n","plt.xlabel(\"Predicted Labels\", fontsize = 'large')\n","plt.ylabel(\"True Labels\", fontsize = 'large')\n","# Loop over data dimensions and create text annotations.\n","for i in range(len(label_names)):\n","    for j in range(len(label_names)):\n","        text = ax.text(j, i, f'{mean_confusions[i, j]:.3f} ± {std_confusions[i, j]:.3f}',\n","                       ha=\"center\", va=\"center\", color=\"black\")\n","\n","ax.set_title(\"Confusion Matrix\")\n","fig.tight_layout()\n","plt.colorbar(im)\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAiwAAAH/CAYAAAB0NYb1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd3hcxb2H8fcnWZY7tnHFBRswOPRi\naqiB0FsIoSckISGN5IZLCjeNkg4JJLmUhFw6CYRQTe89wdgGQ+gYbHADd+OqOvePPZJlq1gWlrXL\nvp/n2ce7c2bnzBFIGn1nzmyklJAkScpnJR3dAUmSpDVxwCJJkvKeAxZJkpT3HLBIkqS854BFkiTl\nPQcskiQp73Xq6A5IkqTWK+21cUrVy9ul7bR8zgMppYPbpfGPyAGLJEkFJFUvp3yL49ql7RWTLu3X\nLg2vAw5YJEkqKAFRfCs6iu+KJUlSwTFhkSSpkAQQ0dG9WO9MWCRJUt4zYZEkqdC4hkWSJKl5EXFV\nRMyOiJcblF0YEa9HxEsRcXtE9G5w7H8iYnJEvBERBzUoPzgrmxwRZ6/pvA5YJEkqNBHt82ida4DV\n92p5CNg6pbQt8CbwP7luxpbACcBW2Xsui4jSiCgFLgUOAbYETszqNsspIUmSCkrH3tacUnoyIkas\nVvZgg5fPAsdmz48CbkopVQBTImIysEt2bHJK6R2AiLgpq/tqc+c1YZEkSevSl4H7sudDgGkNjk3P\nyporb5YJiyRJhab9bmvuFxETGry+IqV0RWvfHBE/BqqBv63rjjlgkSRJdeamlMa05Y0R8UXgcGD/\nlFLKimcAwxpUG5qV0UJ5kxywSJJUSIK8u605Ig4GfgDsk1Ja1uDQWODvEXERsBEwCniO3FWMioiR\n5AYqJwAntXQOByySJKnVIuJGYF9y00fTgXPI3RVUDjwUuemqZ1NKX08pvRIRN5NbTFsNfCulVJO1\ncwbwAFAKXJVSeqXF865MbSRJUr4r6TE4lW9zaru0veLZ305s65RQe8uvTEmSJKkJTglJklRo8mwN\ny/pQfFcsSZIKjgmLJEmFpv32YclbJiySJCnvmbBIklRQOvazhDqKAxZJkgpJ4JSQJElSPjJhkSSp\n0BThlFDxXbFUBCKia0TcFRGLIuKfH6GdkyPiwXXZt44QEfdFRPtsDSppvXDAInWgiDgpIiZExJKI\nmJX9Yt1zHTR9LDAQ2DCl9Lm2NpJS+ltK6cB10J9VRMS+EZEi4vbVyrfLyh9vZTvnRsQNa6qXUjok\npXRtG7sr5Zls0W17PPJYfvdO+hiLiP8G/gD8itzgYjhwGXDUOmh+Y+DNlFL1OmirvcwBdo+IDRuU\nnQq8ua5OEDn+nJM+BvxGljpARGwAnE/uk0tvSyktTSlVpZTuSil9P6tTHhF/iIiZ2eMPEVGeHds3\nIqZHxFkRMTtLZ76UHTsP+BlwfJbcnLZ6EhERI7Iko1P2+osR8U5ELI6IKRFxcoPypxu8b4+IGJ9N\nNY2PiD0aHHs8In4eEc9k7TwYEf1a+DJUAneQ+1h5IqIUOB7422pfqz9GxLSI+DAiJkbEXln5wcCP\nGlzniw368cuIeAZYBmySlX0lO355RNzaoP3fRsQjEUV424UKV0m0zyOPOWCROsbuQBfg9hbq/BjY\nDdge2A7YBfhJg+ODgA2AIcBpwKUR0SeldA651OYfKaUeKaUrW+pIRHQH/gQcklLqCewBTGqiXl/g\nnqzuhsBFwD2rJSQnAV8CBgCdge+1dG7gOuAL2fODgJeBmavVGU/ua9AX+Dvwz4joklK6f7Xr3K7B\nez4PnA70BN5drb2zgG2ywdhe5L52pyY/ul7Kaw5YpI6xITB3DVM2JwPnp5Rmp5TmAOeR+0Vcpyo7\nXpVSuhdYAmzRxv7UAltHRNeU0qyU0itN1DkMeCuldH1KqTqldCPwOnBEgzpXp5TeTCktB24mN9Bo\nVkrpX0DfiNiC3MDluibq3JBSmped8/dAOWu+zmtSSq9k76larb1l5L6OFwE3AN9OKU1fQ3tS/ghc\nwyJpvZkH9KubkmnGRqyaDrybldW3sdqAZxnQY207klJaSm4q5uvArIi4JyJGt6I/dX0a0uD1+23o\nz/XAGcB+NJE4RcT3IuK1bBpqIblUqaWpJoBpLR1MKY0D3iH3o//mVvRRUgdzwCJ1jH8DFcDRLdSZ\nSW7xbJ3hNJ4uaa2lQLcGrwc1PJhSeiCl9GlgMLnU5K+t6E9dn2a0sU91rge+CdybpR/1simbHwDH\nAX1SSr2BReQGGgDNTeO0OL0TEd8il9TMzNqXCktE+zzymAMWqQOklBaRWxh7aUQcHRHdIqIsIg6J\niAuyajcCP4mI/tni1Z+Rm8Joi0nA3hExPFvw+z91ByJiYEQcla1lqSA3tVTbRBv3Aptnt2J3iojj\ngS2Bu9vYJwBSSlOAfcit2VldT6Ca3B1FnSLiZ0CvBsc/AEaszZ1AEbE58AvgFHJTQz+IiBanriR1\nPAcsUgfJ1mP8N7mFtHPITWOcQe7OGcj9Up0AvAT8B3g+K2vLuR4C/pG1NZFVBxklWT9mAvPJDR6+\n0UQb84DDyS1anUcumTg8pTS3LX1are2nU0pNpUcPAPeTu9X5XWAFq0731G2KNy8inl/TebIpuBuA\n36aUXkwpvUXuTqPr6+7AkvJfce7DEi6MlySpcJT0GprKd/12u7S94uGzJ6aUxrRL4x9Rfg+nJEmS\n8MMPJUkqPHk+fdMeiu+KJUlSwTFhkSSpkBTALcjtwYRFkiTlPROWtRSduqbo3LOjuyHljR0+Mbyj\nuyDljXffncrcuXPbP/4owjUsDljWUnTuSfkWx3V0N6S88cy4Szq6C1Le+OSueXlH8MeCAxZJkgqN\na1gkSZLyjwmLJEkFJYpyDUvxXbEkSSo4JiySJBWaIlzD4oBFkqRCEjglJEmSlI9MWCRJKiguupUk\nScpLJiySJBWaIlx0a8IiSZLyngmLJEmFxjUskiRJ+ceERZKkQuMaFkmSpPxjwiJJUiEJ92GRJEnK\nSyYskiQVmiJcw+KARZKkAhNFOGBxSkiSJOU9ExZJkgpIYMIiSZKUl0xYJEkqJJE9iowJiyRJynsm\nLJIkFZRwDYskSVI+MmGRJKnAmLBIkiTlIRMWSZIKjAmLJElSHjJhkSSpwBRjwuKARZKkQuLGcZIk\nSfnJhEWSpAISbhwnSZLUsoi4KiJmR8TLDco+FxGvRERtRIxZrf7/RMTkiHgjIg5qUH5wVjY5Is5e\n03kdsEiSVGAiol0erXQNcPBqZS8DxwBPrtbPLYETgK2y91wWEaURUQpcChwCbAmcmNVtllNCkiSp\n1VJKT0bEiNXKXoMm7146CrgppVQBTImIycAu2bHJKaV3svfdlNV9tbnzOmCRJKnAtOMaln4RMaHB\n6ytSSld8hPaGAM82eD09KwOYtlr5ri015IBFkiTVmZtSGrPmauufAxZJkgpMAd0lNAMY1uD10KyM\nFsqb5KJbSZLUXsYCJ0REeUSMBEYBzwHjgVERMTIiOpNbmDu2pYZMWCRJKiQdvNNtRNwI7Etuvct0\n4BxgPvC/QH/gnoiYlFI6KKX0SkTcTG4xbTXwrZRSTdbOGcADQClwVUrplZbO64BFkiS1WkrpxGYO\n3d5M/V8Cv2yi/F7g3tae1wGLJEkFpoDWsKwzDlgkSSogbs0vSZKUp0xYJEkqMCYskiRJeciERZKk\nQlN8AYsJiyRJyn8mLJIkFZJwDYskSVJeMmGRJKnAmLBIkiTlIRMWSZIKjAmLJElSHjJhkSSpgPhZ\nQpIkSXnKhEWSpEJTfAGLAxZJkgqKG8dJkiTlJxMWSZIKjAmLJElSHjJhkSSpwJiwSJIk5SETFkmS\nCk3xBSwmLJIkKf+ZsEiSVGBcwyJJkpSHTFgkSSogEX74oSRJUl4yYZEkqcAUY8LigEWSpAJTjAMW\np4QkSVLeM2GRJKnQFF/AYsIiSZLynwmLJEkFxjUskiRJeciERZKkQhImLJIkSXnJhEWSpAISQBEG\nLCYskiQp/5mwSJJUUPzwQ0mSpLxkwiJJUoEpwoDFAYskSYXGKSFJkqQ8ZMIiSVIhieKcEjJhkSRJ\nec+ERZKkAhJASUnxRSwmLJIkKe+ZsEiSVGBcw6KPvar3HmHFy1dR8fqNq5bPeIaK1/5Gxes3UTnl\nXlJ1BQCpegWVk+9gxUt/oWr6k6u8J9XWUDXtMSpeu4GK1/5GzcK3G52vZvE0Kt64mYrXb6TijZup\nWTy9/ljtstm58levp2r6k6SUGpzzTipevYHKyXeSqld85OuunvMSFa9ez4pJl5Kql6/s3/w3qHj9\nplw/3ryV2uVzs2urpuLNf2bH/k7VrHHNtl2z4C0qXvs7Fa//ncqpD2bXNoeKN2+h4vW/U/H6TdQs\neKu+ftV7j2bt3kTllPtJNZUf+fr00W2x2QjGbL8Nu+60PZ/cdUx9+Xnn/JSdd9iWXXfansMPOZCZ\nM2cCkFLiv7/7HbYavRk777AtLzz/fIvtH/uZI9lp+63rX8+fP5/DDv40W39iFIcd/GkWLFjQpnZb\n4+mnnmT3nXekR5dO3HbrLfXlL06axD577s6O223Fzjtsyz9v/kf9sa9/9TR22XE7dt5hW048/liW\nLFnSqN158+Zx0AH70a93D777nTNWOXbkYQezy47bseN2W/Htb36dmpoaAH5x/rlssvEQdt1pe3bd\naXvuv+/ej3x9Kg7rZcASEY3/T1+37T8eEWOaKN8+Ig5tz3MXmtK+n6DzJkc0Ki/pOYzOo0+kfPQJ\nRHlvqmdPzB2IUjoN2oVOG32y0XuqP5gAnbpS/olT6Dz6JEp6bNSoTpR2ofMmh1E++kTKhu9P1XsP\n1x+rmv4EZcP2o/MnTiFVLKJ28Xu5dmc/T0nPoZRveQolPYdSPbvlH9hVs56jet5rLdYp6T6Ysk2P\ngrKeq/avvBedNzua8tEn0mnQGKqmPVZ/3Z03PYry0SfQeYvjqV38HrVL32/Ubm3FQqpnP0/nUcdQ\nPvokyobsmZ2wjLKND6B89El03vQIqmY8XT8I7DRkT8pHn5D7WnfuQc3c/7TYd60/9z/8GOMmTuKZ\ncRPqy8486/uMf+Elxk2cxCGHHs6vf3E+AA/cfx9vT36Ll197i0suv4LvnPGNZtu94/bb6N6jxypl\nv7vgN+z7qf15+bW32PdT+/O7C36z1u0CPPnE43z1y19ssc6wYcO54sprOP6Ek1Yp79atG1defR3P\nv/gKd95zPz8467ssXLgQgAt+fzHPPf8i4194iWHDhnP5ZZc0ardLly787Nyf8+vf/q7RsRtuvJnn\nnn+RiZNeZs7cOdx6yz/rj337v85k3MRJjJs4iYMP8Ud0W0REuzzy2cc9YdkeWKvvhoj4WE+TlfTY\nCErLG5WX9hpORO5/h5Jug0hVuTFmlJbl3hOljd5TM/91Og3YKVcvgujUtfH5uvUnyrrn6nTpC7XV\npNoaUtVSqKmkpPsgIoLSvltQu+gdAGoXTaG07+hcv/qOpnbRlI9+3d36U1Leq3F598FEpy5ZnYG5\nftVdT2nnXKVUm3s0oWbeq5T226a+jSjrlmurS29KyntnZd2JTl1JNblkp67dlBLUVpNbQqd81avX\nyv9vli1bWv9D/e6xd3LSKV8gIth1t91YtGghs2bNavT+JUuW8Kc/XMTZ//OTVcrvvutOTvn8qQCc\n8vlTuWvsHWvV7trYeMQIttl2W0pKVv2RP2rzzdls1CgANtpoI/r3H8DcOXNWue6UEiuWL2/yl1n3\n7t355J570qVLl0bH6t5fXV1NVWVl3v8yVP7rsAFLRBwREeMi4oWIeDgiBmbl50bE9xrUezkiRmTP\nfxoRb0TE0xFxY8N6wOci4rmIeDMi9oqIzsD5wPERMSkijo+I7hFxVVbvhYg4Kmv3ixExNiIeBR5Z\nX1+DfFUz/zVKe27cYp26tKD6/XFUvPGP3NRG1bIW31O76G1KuvYnSkpJVUuJspV/cUZZj/rBQqpa\nVj/IoVO3JtutXT6vflqlZt7LVL//XP3rtk4h5a57+MprTLW5Nl++ipKewyjpPqjRe9KKhaSKhVS8\ndSsVb95CzYfvNu7r0g8g1RKdN6gvq3rvESpeuZpUsZDS/tu0qb9atyKCIw45kD122Ykr/3rFKsfO\n+emP2WzkMG668W/89NxcwjJz5gyGDh1WX2fIkKHMnDGjUbvnnfNT/uvMs+jWrdsq5bM/+IDBgwcD\nMGjQIGZ/8MFatbvXHruy607b842vfYV77h5bP8Xy0IMPtOn6xz/3HJVVlWyy6ab1Zaef9iVGDB3E\nG2+8zje/9e21bvOIQw9i+EYD6NGzJ8d89tj68j9fdgk777AtX/vKl+unwrQWsn1Y2uORzzoyYXka\n2C2ltANwE/CDlipHxM7AZ4HtgEOA1aeAOqWUdgG+C5yTUqoEfgb8I6W0fUrpH8CPgUezevsBF0ZE\n9puRHYFjU0r7NHHu0yNiQkRMaLj+4eOo+v0JEEFJn83XULMWqpZQ0n0Q5VscT0n3QVTNfKb52svn\nUT3z33Qatu9a9Sea+S4q6bph/bRK6YZb02nQLiunWTo1/mtvTWoWT6dm3mt02miPBucuybW55RdJ\ny2ZTu3xeE++sJVUspPNmR1O28YFUTXu8fjAHkKqWUvXew5QN/9Qqf2GWDd+f8q2+SJT3oWbB5LXu\nr9a9Rx5/mn+Pf5477r6Pv1x+KU8/tXLN1nk//yWTp0zjhBNP5s9NTI0058VJk5jyztscdfRnWqzX\nljj+qX+NY9zESVz+l//jsMOPrJ9i+fSBB61VOwCzZs3itC99nr/89epVUpgrrryad96byejRn+CW\nButbWuuuex9gyrRZVFRU8PhjjwLw1a99g1ffeJtxEycxaPBgzv7+WWvdropTRw5YhgIPRMR/gO8D\nW62h/ieBO1NKK1JKi4G7Vjt+W/bvRGBEM20cCJwdEZOAx4EuQN2f1A+llOY39aaU0hUppTEppTFN\nTXt8XFTPe42aD6dStvGn1/zDs7QLlHSiZIPcX2OlvTclLZ/TZNVUuYSqqfdRNvwASspzKUOUda+f\ndgJIVUtWTh2VdWuQtixtcqppXapdPpfqaY9RNvLQJgc70amckh5D6tfYrHKsrAclvUYSUUpJeS9K\nyjcgVebWAKSaSirfuZtOg3dtMp2JKKG0zyhqFzVerKz1b8iQIQAMGDCAI4/+DOPHP9eozvEnnswd\nt98KwEYbDWH69Gn1x2bMmM5GWRt1xj37byZOnMAWm43gU/vuyVtvvsmB+++bO8/AgfVTPbNmzaL/\ngAGtbndd+vDDDznmyMM49/xfsutuuzU6XlpayueOP6H+utdWly5dOOKIo7hr7J0ADBw4kNLSUkpK\nSvjyaV9lwoTGX2e1LHANy/r2v8AlKaVtgK+RGzwAVLNqv1r753Ldn7U1NH+7dgCfzRKX7VNKw1NK\ndas1l7a+6x8/NR++S83sF+i8yWFESdka60cEJb1GULskF1XXLJ5OlPdtVC9VV2S/tHenpMfgle8v\n6w6lnald+j4pJWrmv0HJBiMBKOk1gpr5r+fanf96fXlzygbvQqcNP9Hqa12lf5WLqZpyH2UbH0BJ\nl94N+r185Z1StdXULJ5GlPdp9P6SDUbWfw1S9XJqKxYRnTfI3UE15V5K+4ymtPdmK9tNidqKhfXP\naxZNabJdrV9Lly5l8eLF9c8ffuhBttoqd0fP5LdW3uF199g72XyL3Pqqw444kr/fcB0pJcY9+yy9\nem1QP8VT5/Svf4Mp783kjclTefTxpxm1+eY8+MjjufcffiQ3XH8tADdcfy2HH3FUq9ttaO999uWv\nV13TpuuurKzk+GM/w0mnfGGVKZuUEm9Pnlz//O67xtZfd2ssWbKkfjBWXV3NfffdwxbZ+xuux7nz\njtvZcqutm2xDLWmfwUq+D1g6coHpBkDdxOypDcqnAocDRMSOQN1vq2eAv0TEr8n1+3Bg1YnmxhYD\nDW8LeQD4dkR8O6WUImKHlNILH+kqCkzl1Adzv2CrV7DilWtydwBtuCXV058kpVoqJ+f+CirpPoiy\nbPpmxSvXQW0lpBpqFr1D502PpKRLX8o22p3Kdx+mesbTRKculA3fH4CaRVOoXTabssG7UjP3P6TK\nRVS/P57q98cD0HnTI4mybpQN3Yeq9x6B2mpKem1MSbZuptPAnaiaej8V814jOvekbETjiLt2+Tyq\n3n2oyWvsvNnRjZKS6jkvUj37BahaRsXrN1Haa2PKhn+K6vfHk2oqqJr2RK5ilFC+xXHZVM4jkBKQ\nKO29GaUbjACgatY4SroNoHSDkZT0HE7t4mlUvPZ3iKBsoz2ITl2omf8GtUtmkapXUDM/NyYuG74/\n0bVfrt3sVubouiFlQ/dt039LrTuzP/iA44/NTdtU11Rz/AknceBBBwPwkx+fzVtvvkFJlDB84435\n06V/BuDgQw7lgfvuZavRm9Gtazf+8n9X17e3607bM27ipBbP+b0fnM0pJx7HtVdfyfDhG3PDjTev\nsd2G9tpjVyorKhqV/+LXv200LTRh/HiO/9xnWLhgAffecxe/OP8cnn/xFW795808/dSTzJ83jxuu\nuwaAK668hm223ZavfPlUFn/4IYnENttsx58uvRyAu+8ay/MTJ/CzbC3PFpuNYPGHH1JZWcldY+/g\n7nsfpO+GG3LsZ46ksqKC2lTL3vvsx1e/9nUAfnz2D3jpxUlEBBuPGMH/XvaXFr9OUp2o2/uiXU8S\nUQvMbFB0EfA2cDGwAHgU2DmltG9EdAXuBIYA44DdgUNSSlMj4lzgJOADYDZwf0rprxHxOPC9lNKE\niOgHTEgpjYiIvuQGKWXAr4GxwB+APcilOFNSSodHxBeBMSmlVTcSaEJJtwGpfIvjPtoXRPoYWTC+\n9Ws6pI+7T+46hokTJ7RrVNFtoy3S5qdf1i5tv3jeARNTSo22CckH6yVhSSk1N/V0ZxN1l5Nba9KU\n36WUzo2IbsCT5NarkFLat8H755KtYcnWpOy8Whtfa+Kc1wDXtHAJkiSpAxXaniNXRMSW5Na1XJtS\n+uhbQEqSVGDyfb1JeyiojeNSSidli2VHp5R+3dH9kSSp2GT7mc2OiJcblPWNiIci4q3s3z5ZeUTE\nnyJickS8lK1NrXvPqVn9tyLi1KbO1VBBDVgkSSp6Hb9x3DXAwauVnQ08klIaRW4D1rOz8kOAUdnj\ndOByyA1wgHOAXYFdgHPqBjnNccAiSZJaLaX0JLD6vmVHAddmz68Fjm5Qfl3KeRboHRGDgYPI9j9L\nKS0AHqLxIGgVhbaGRZKkola3cVyeGZhSqttk531gYPZ8CDCtQb3pWVlz5c1ywCJJkur0i4gJDV5f\nkVJa055nq8j2OVvne6Y4YJEkqcC0Y8Ayt437sHwQEYNTSrOyKZ/ZWfkMYFiDekOzshnAvquVP97S\nCVzDIkmSPqqxrNy1/lRW7rM2FvhCdrfQbsCibOroAeDAiOiTLbY9MCtrlgmLJEkFpiPXsETEjeTS\nkX4RMZ3c3T6/AW6OiNOAd4G6LeHvBQ4FJgPLgC9BbmPXiPg5MD6rd35zH0BcxwGLJEkFpiPX3KaU\nTmzm0P5N1E3At5pp5yrgqtae1ykhSZKU90xYJEkqJJGXtzW3OxMWSZKU90xYJEkqILmN4zq6F+uf\nCYskScp7JiySJBWUcA2LJElSPjJhkSSpwBRhwGLCIkmS8p8JiyRJBcY1LJIkSXnIhEWSpEISxbmG\nxQGLJEkFJLdxXPGNWJwSkiRJec+ERZKkAmPCIkmSlIdMWCRJKjBFGLCYsEiSpPxnwiJJUoFxDYsk\nSVIeMmGRJKmQFOnGcSYskiQp75mwSJJUQIJwDYskSVI+MmGRJKnAFGHA4oBFkqRCU1KEIxanhCRJ\nUt4zYZEkqcAUYcBiwiJJkvKfCYskSQUkwq35JUmS8pIJiyRJBaak+AIWExZJkpT/TFgkSSowrmGR\nJEnKQyYskiQVmCIMWExYJElS/jNhkSSpgAQQFF/E4oBFkqQC423NkiRJeciERZKkQhLhbc2SJEn5\nyIRFkqQCU4QBiwmLJEnKfyYskiQVkABKijBiMWGRJEl5z4RFkqQCU4QBiwmLJEnKfyYskiQVGPdh\nkSRJykOtGrBExH4RMTJ7Pjgiro2IqyNiUPt2T5IkNRTRfo981tqE5TKgJnv+e6AMqAWuaI9OSZKk\n5pVEtMsjn7V2DcuQlNJ7EdEJOAjYGKgEZrZbzyRJkjKtHbB8GBEDga2BV1NKSyKiM7mkRZIkrUf5\nnYW0j9YOWP4XGA90Br6blX0SeL09OiVJktRQqwYsKaXfRsTtQE1K6e2seAbwlXbrmSRJalIx3tbc\n6n1YUkpvtvRakiSpvTQ7YImIaUBaUwMppeHrtEeSJKlZuQ8/7OherH8tJSynrLdeSJIktaDZAUtK\n6Yn12RFJktQKEUW5hqW1O92WR8QvI+KdiFiUlR0YEWe0b/ckSVI+iYj/ioiXI+KViPhuVtY3Ih6K\niLeyf/tk5RERf4qIyRHxUkTs2Nbztnan24vJ7cFyMivXtbwCfKOtJ5YkSW3TUVvzR8TWwFeBXYDt\ngMMjYjPgbOCRlNIo4JHsNcAhwKjscTpweVuvubUDls8AJ6WU/k1uS35SSjOAIW09sSRJKjifAMal\nlJallKqBJ4BjgKOAa7M61wJHZ8+PAq5LOc8CvSNicFtO3NoBSyWrrXeJiP7AvLacVJIktV1k61jW\n9aMVXgb2iogNI6IbcCgwDBiYUpqV1XkfGJg9HwJMa/D+6bQx7GjtPiz/BK6NiDMh94nNwB+Am9py\nUkmS1DbtfFtzv4iY0OD1FSml+g86Tim9FhG/BR4ElgKTWPnhyHV1UkSscVuUtdXahOVHwBTgP0Bv\n4C1yH3x43rrukCRJ6jBzU0pjGjyuWL1CSunKlNJOKaW9gQXAm8AHdVM92b+zs+ozyCUwdYZmZWut\nVQOWlFJlSunMlFIPcjFPz+x1ZVtOKkmS2q4Dp4SIiAHZv8PJrV/5OzAWODWrcipwZ/Z8LPCF7G6h\n3YBFDaaO1kqrt+aPiFHAccBGwMyIuDml9FZbTipJkgrWrRGxIVAFfCultDAifgPcHBGnAe+SGy8A\n3EtunctkYBnwpbaetFUDlmtNeOAAACAASURBVIg4CbgCuCfryDbA2RHxtZTS39t6ckmStPY6ctu4\nlNJeTZTNA/ZvojwB31oX521twvIL4NCU0pN1BRGxF3A9uShIkiSp3bR2wNIT+PdqZc8C3ddtdyRJ\nUksioMSt+Zt1EfCriOgCEBFdgV9m5ZIkSe2q2YQlIqaxchv+AAYB/xURC4A+Wdks4Nft3UlJkrRS\nEQYsLU4JnbLeeiFJktSCZgcsKaUn1mdHJElS67R2z5SPk7XZh2V7YC+gHw3uqEop/awd+iVJklSv\ntfuwnA5cTO6zAw4B7gMOZOVOdpIkaT0pwoCl1QnLD4CDU0pPRcSClNJnIuIQ4IR27JskSVpNEN7W\n3IIBKaWnsue1EVGSUroPOKKd+iVJklSvtQnL9IgYkVKaSu5TGY+KiLmAH34oSdL6FE4JteQC4BPA\nVOB84BagM/Bf7dMtSZKklVo1YEkpXdPg+X0R0YfcgGVZO/VLkiQ1w9uaWymlVBm5r1YVULpuu5Tf\nRm82hBtu/1VHd0PKG5uccVtHd0HKG3PfW9jRXfjYatOApYHiG+JJktTBWnvHzMfJR73mtOYqkiRJ\nH81HTVgkSdJ6FLiGpZGIeIrmU5RiTKQkSVIHWFPC8n9rOP7XddURSZLUOiXFF7C0PGBJKV27vjoi\nSZLUHNewSJJUYExYJElSXosozkW3LpyVJEl5z4RFkqQCU4xTQq1KWCKiPCJ+GRHvRMSirOzAiDij\nfbsnSZLU+imhi4GtgZNZuS/LK8A32qNTkiSpebl1LOv+kc9aOyX0GWCzlNLSiKgFSCnNiIgh7dc1\nSZKknNYOWCpXrxsR/YF567xHkiSpWQGU5Hsc0g5aOyX0T+DaiBgJEBGDgUuAm9qrY5IkSXVaO2D5\nETAF+A/QG3gLmAmc1079kiRJzShpp0c+a9WUUEqpEjgTODObCpqbUmruQxElSZLWqVYNWCJik9WK\netbtspdSemddd0qSJDWvCJewtHrR7WRytzM3/BLVJSyl67RHkiRJq2ntlNAqU1sRMQg4B3iqPTol\nSZKaFhFFeZdQm7bmTym9HxHfBd4E/r5uuyRJklpShOOVj7QoeAug27rqiCRJUnNau+j2KVauWYHc\nQGUr4Pz26JQkSWpeMX74YWunhP5vtddLgRdTSm+t4/5IkiQ1ssYBS0SUAp8CTk8pVbR/lyRJUnPc\nmr8ZKaUa4ECgtv27I0mS1FhrF91eDJwXEWXt2RlJkrRmEe3zyGctDlgi4sTs6beB7wOLI2JaRLxX\n92j3HkqSpKK3pjUsfwFuBE5ZD32RJElrEt4l1JQASCk9sR76IkmS1KQ1DVhKI2I/Vv0MoVWklB5d\nt12SJEktieZ/LX9srWnAUg5cSfMDlgSs/knOkiRJ69SaBixLU0oOSCRJyhO5fVg6uhfrX5s+/FCS\nJHWcYhywrGkfliL8kkiSpHzTYsKSUuq5vjoiSZJaJ/J9l7d20NqdbiVJkjqMa1gkSSogxbro1oRF\nkiTlPRMWSZIKSQF8UGF7MGGRJEl5z4RFkqQCU1KEEYsJiyRJynsmLJIkFRDvEpIkScpTJiySJBWY\nIlzC4oBFkqTCEpQU4Uf9OSUkSZJaLSLOjIhXIuLliLgxIrpExMiIGBcRkyPiHxHROatbnr2enB0f\n0dbzOmCRJKmABLkpofZ4rPHcEUOA7wBjUkpbA6XACcBvgYtTSpsBC4DTsrecBizIyi/O6rWJAxZJ\nkrQ2OgFdI6IT0A2YBXwKuCU7fi1wdPb8qOw12fH9o40fNe0aFkmSCkm0623N/SJiQoPXV6SUrqh7\nkVKaERG/A94DlgMPAhOBhSml6qzadGBI9nwIMC17b3VELAI2BOaubcccsEiSpDpzU0pjmjsYEX3I\npSYjgYXAP4GD10fHHLBIklRgOnBr/gOAKSmlOQARcRvwSaB3RHTKUpahwIys/gxgGDA9m0LaAJjX\nlhO7hkWSJLXWe8BuEdEtW4uyP/Aq8BhwbFbnVODO7PnY7DXZ8UdTSqktJzZhkSSpgNTdJdQRUkrj\nIuIW4HmgGngBuAK4B7gpIn6RlV2ZveVK4PqImAzMJ3dHUZs4YJEkSa2WUjoHOGe14neAXZqouwL4\n3Lo4rwMWSZIKTAeuYekwrmGRJEl5z4RFkqQCU4QBiwMWSZIKSVCc0yPFeM2SJKnAmLBIklRIAtr4\ncTwFzYRFkiTlPRMWSZIKTPHlKyYskiSpAJiwSJJUQAI3jpMkScpLJiySJBWY4stXTFgkSVIBMGGR\nJKnAFOESFhMWSZKU/0xYJEkqKFGUO906YJEkqYD44YeSJEl5yoRFkqQCU4xTQiYskiQp75mwSJJU\nYIovXzFhkSRJBcCERZKkQhKuYZEkScpLJiySJBUQ92GRJEnKUyYskiQVGNewSJIk5SETFkmSCkzx\n5SsOWCRJKjhFOCPklJAkScp/JiySJBWQ3G3NxRexmLBIkqS8Z8IiSVKBcQ2LJElSHjJhkSSpoATh\nGhZJkqT8Y8IiABZ/uJCf//DbTH7zNSKCcy64lG133IWzz/gi774zOauziJ69NuDGe59m5vR3OfaA\nXdh4k1EAbLPDGH70yz80avcPv/oJTz5yP2VlnRm68UjOvfBSevbqDcBVl/2eO2++ntKSUr53zm/Z\nY58DAPjXEw/zu/N+SE1tDUcf/wW+9I3//kjXNv7fT3LRz39U/3rq22/yq/+9iv0OPJwff/crvPbS\nC3QqK2Or7XbiR7/8A2VlZau8f9b09zjr6yeTahPV1VUcf+rpHHvyaQCcfsJhzJ39PuVdugJw6XW3\n07dff2ZNf4/zfvgtFsybxwa9+/Dzi69g4OAhH+k61L4WPn4pFe9OoKTrBvQ/buX/y7UrFrPg4Yuo\nWTyb0p4D6PPpsygp78GSSXewfPJTWaUaqhfOYOAXrqKkS89m22pK5ezJzLvjf+h9wH/TdZPdAVj2\nxmMsef4WAHrseCzdttgPgKo5b7Pw8UtI1ZWUD9+RXnt8+SNt0V69cAYLHr6o/nXNhx/Qc8wJdN/2\ncD7897WseG8CUdKJ0l6D6L3vGZSUd2/Uxor3XuDDf10FqZZuo/enxw7H5L6ej/0vlbNeJTp3A6D3\nvmdQ1m9ki9et1ivGNSx5MWCJiARclFI6K3v9PaBHSuncNrTVGzgppXRZG947FRiTUpq7tu8tdBee\ndza773MAF1x+PVWVlaxYsQyA31xyTX2di37xY3r06lX/eujGI7nx3qdbbHfXPffjjB+cS6dOnfjT\nb37G1ZddxHfOPp933nqdB++6jX8+MI45s2fxjVOO4vZHn8+d82dncdn1dzBw0BA+f9R+7HPAoWwy\nanSz5zh8z224++n/NHt85933ru/nooXzOXrfHdhtr08BcMhRx/GLi/8KwI//6zTu+Me1fO6Ur6zy\n/n4DBnHNrQ/TubycZUuXcNxBu7PPAYfSf+BgAH7xh7+y5bY7rvKei3/1Ew475kSO+OxJPPevJ7jk\ngvP4+cVXtPi1Usfquvm+dN/qEBY+9qdVypdMup3yIdvQY4djWPLCbSx54XZ67fZ5emx/ND22PxqA\nFVPHs/Q/d1PSpWeLba0u1daweNz1lA/drr6sdsVilky8mX7HXAARzL31+3QZsTMl5T1Y9NQVbLD3\nNygbMIoF9/2Simkv0GX4js22P2/sz9hgvzPo1HNAk8c79R5C/2N/X9+X2TecTvnIXQAoH7odPXc9\nhSgp5cNnr2fJC7fRa7fPN+r/h8/8lb6H/YzS7hsy97YfUj5iZ8r6DAOg525faHIw0tR1S2uSL1NC\nFcAxEdFvHbTVG/hmUwciIi8GaPlm8YeLeOG5Zzj6+C8AUNa5c30KUielxMP33s7BRxy7Vm3vvvf+\ndOqU+7JvvcPOfPD+TAAef+geDjziGDqXlzNk2AiGbbwJr7w4kVdenMiwjTdh6PCRlHXuzIFHHMPj\nD92zDq4y55F772SPfT9N1665v/r23O9AIoKIYKvtdmL2rJmN3lPWuTOdy8sBqKyspDbVrvE8Uya/\nwc677w3kBkxPPHzvOrsGtY/yjbYiuvRoVL5i6ni6bp5LOLpuvh8rpj7XqM7yt5+m62Z7rrGt1S17\n+T66jNyNkq4b1JdVTJ9E+dDtKOnSk5LyHpQP3Y6KaS9Qs3QBtVXL6DxwcyKCrpvvQ0UTfWmryhn/\nobTXwPrBTfmw7YmSUgA6D9ycmqXzGr2navZkSnsNolOvQURpGV0325OKqePXeK6mrlutV7cPS3s8\n8lm+DFiqgSuAM1c/EBH9I+LWiBifPT6ZlZ+bJTF19V6OiBHAb4BNI2JSRFwYEftGxFMRMRZ4Nat7\nR0RMjIhXIuL09XB9eW3m9Hfp07cf537/m5x02J6c/8MzWL5s6Sp1XnjuX/Tt15/hIzetL5sx7V1O\nOmxPvnr8obzw3L/WeJ6xN9/AJ/f5NABz3p/FoMFD648NHLwRs9+fyez3Z64ydTJw0BDmvD+rUVtX\nXnIhJx66JyceuidzZs+qf/6bn57VYh8euPtWDmpi0FVVVcU9t99UPy21uvdnTuf4g/fg0D225Itf\n+259ugJw7g++xYmH7slf/3QBKSUARn1iax594C4AHnvgLpYuWczCBfNb7JvyU+3yhZR27wNASbfe\n1C5fuMrxVFVBxbRJdBm521q1W7N0HiumjqPbVgetVj6fkh4r/3Yr6b4hNUvnU7NsHqXdN6wvL83K\nV7fs9UeZc8tZzLnlLKrmvM2Ce3/JnFvOYv4Dv22xP8vffmaVQdeqbT5C+bAdGl/DsvmUrtLXvqsM\nbBY/93fm/PNMPvzX1aSaqhavW1qTfEocLgVeiogLViv/I3BxSunpiBgOPAB8ooV2zga2TiltDxAR\n+wI7ZmVTsjpfTinNj4iuwPiIuDWl1PjPhyJRU13N66+8yPfPvZBtdhjDhef9kKsvv5hvnvWT+jr3\n33XLKr/o+/UfxD3PvELvPn157T8vcNbXTubmB56lR89eTZ2CKy+5kNJOnTjk6OPWSZ9PO+P7nHbG\n94HclNCapqYA5sx+n8lvvMrue+/f6Nhvfvrf7LjLJ9lhlz2afO+gjYbyj/v/xZwPZnHW6Sex/yFH\nsWH/AfziD39lwKCNWLpkMd//xue557abOPyzJ3Lmj37Bb8/5Hnff8jd22OWTDBi0EaWl+fL3gdoq\nt15k1b9CV7w7gc4Dt6ifDmqtD/91NT13/TwR6/b/i26jP0W30bkpzzVNCdVJNVWseHc8PXc5udGx\nxc/fAiWldB2191r1o+cup1DSrTfUVrPoyT+zZNLt9NzpuHa77qISrmHpUCmlDyPiOuA7wPIGhw4A\ntmywsKxXRKw5a13Vcw0GKwDfiYjPZM+HAaOAZgcsWQpzOsCgjYat5anz34DBQxgwaAjb7DAGgAMO\nOYqr/3xx/fHq6moeu/8ubrjrifqyzuXl9dMkn9hmB4YOH8l7UyY3WssBMPaWv/HUow9w+d/G1i8Q\n7D9oMO/Pml5f54NZMxkwaKPs+YyV5e/PoP+gwawLD91zO/sdeHijRbVX/PE3LJg/jx//6o9rbKP/\nwMFsusWWvDD+Xxxw6NH1fe7eoycHH/U5XnlxIod/9kT6DxzM7/78NwCWLV3Co/ePbTTNpsJQ0rU3\nNUsXUNq9DzVLFzSaxshNB+211u1WzXmbhdmC19oVi6l473kiSijt3pfKma/U16tdOo/OG21FabcN\nV0kvapbOo7R73zZe1aoqpr1AWb9NKO226v+jy954lIp3J7Lh4ec2ubi3tFtfapasXPJXu3R+fQpU\nl0pRWkbXLfZj6YtjW7zuLiN3XSfXUiyKccCSb0PcPwCnAQ2XopcAu6WUts8eQ1JKS8hNIzXsf5cW\n2q2f38gSlwOA3VNK2wEvrOG9pJSuSCmNSSmN6bPhhi1VLUj9+g9k4OAhTH37LQCe+9cTbLLZFvXH\nn3vmcUZsuvkqUzUL5s2lpqYGgOnvTeG9qW8zZPiIRm3/64mHue4vf+Tiv95Uv24EYJ8DDuXBu26j\nsqKCGdOmMm3q22y13U5sue2OTJv6NjOmTaWqspIH77qNfQ44tMX+t7TgtqEHxt7CQUeuOh10+03X\n8u8nH+FXf7qSkpKmvx0+mDWDFStyY+gPFy1g0vh/s/Emo6iurmbB/NwvkKqqKp5+5H423SIX/i2Y\nP4/a2txal6svu4gjP3dKq/qo/NNl4zEsf/MxAJa/+RhdRuxcf6y2YimVs16lvEFZaw046XIGnPxn\nBpz8Z7psshu99jqdLiN3pXzo9lRMf5HaiiXUViyhYvqLlA/dntLufSgp60blB2+SUmL5m0+s8bwb\nHnn+GtMVgOWTn6brpqtOB6147wWWTrqTPgefTZSVN/m+sgGbUbNoFtUffkCqqWL55Kcp3zj3h0/N\n0gVAbv3biinP0anvsBavW1qTvElYALJpmpvJDVquyoofBL4NXAgQEdunlCYBU4HDs7Idgbr75RYD\nLWWzGwALUkrLImI0sHYTzx9TPzjvAn5y5leoqqxiyPARnHvhpfXHHrjrVg468rOr1H/+uWf488W/\nolOnMqIk+NEvLmaD3rm/9s7/4Rkce/KX2XLbHfntOd+jqrKSb34+dzdF3e3Pm27+CT592NEce+Au\ndCrtxA/P/z2lpaVZX37HGV84hpraGo763ClsunnjGcArL7mQh++9s1H5djvtytk//32j8pnT3+WD\nWTPYaddVfyj/+idnMmjIML50TG5tzX4HH8Hp3/khr770PLf87Sp+9ttLmDL5DS7+5U+ICFJKfP6r\n32bU6K1YvmwpZ5z6GaqrqqmtrWGXT+7LZ074IgATn32KSy48jyDYYZc9OPv8xn1Sflnw8EVUznqF\n2hWL+eCGr9JzzPF0G30APXY4hgUP/Z5lrz9Cac/+9Dlg5TqpFVPH5RbIlnVpVVtLX30AgO5bNr9+\no6RLT3rseCxzb/shAD12/Fz9dFOvvb7KoscuIdVUUj5sB8qHNU40l73+KEtfbrxQvbTnAPoe9MNG\n5bVVK6iY/iIb7PW1Vco/fOb/SDVVzL/nfAA6D9icDfb+GjVL57Poicvoe+hPiJJSeu35Febf+3NI\ntXTd4lOU9R0OwMJH/0Dtig8hJTptOJIN9i765YLrVDFuHBd1iwQ7tBMRS1JKPbLnA4EpwAUppXOz\nO4cuJbdupRPwZErp69n6kzuBIcA4YHfgkJTS1Ij4O7AtcB9wD/C9lFLd4KYcuAMYAbxB7q6ic1NK\nj7fmtuYtt90h3TD2ieYOS0Xn8N883NFdkPLG3Ft/QOWcye06mth86+3Tpf9sn++7A7fsPzGlNKZd\nGv+I8iJhqRusZM8/ALo1eD0XOL6J9ywHDmymvZNWK3q8wbEK4JBm3jdiLbotSdJ6F0BJ8QUsebeG\nRZIkqZG8SFgkSVLrFeMaFhMWSZKU90xYJEkqMO7DIkmSlIdMWCRJKjCuYZEkScpDJiySJBWQYt2H\nxQGLJEkFJZwSkiRJykcmLJIkFZLwtmZJkqS8ZMIiSVKBKcKAxYRFkiS1TkRsERGTGjw+jIjvRkTf\niHgoIt7K/u2T1Y+I+FNETI6IlyJix7ae2wGLJEkFJHdbc7TLY01SSm+klLZPKW0P7AQsA24HzgYe\nSSmNAh7JXgMcAozKHqcDl7f1uh2wSJKkttgfeDul9C5wFHBtVn4tcHT2/CjgupTzLNA7Iga35WQO\nWCRJKjDRTo+1dAJwY/Z8YEppVvb8fWBg9nwIMK3Be6ZnZWvNAYskSarTLyImNHic3lSliOgMHAn8\nc/VjKaUEpHXdMe8SkiSp0LTfbUJzU0pjWlHvEOD5lNIH2esPImJwSmlWNuUzOyufAQxr8L6hWdla\nM2GRJElr60RWTgcBjAVOzZ6fCtzZoPwL2d1CuwGLGkwdrRUTFkmSCkxHfpZQRHQHPg18rUHxb4Cb\nI+I04F3guKz8XuBQYDK5O4q+1NbzOmCRJKnAdOTW/CmlpcCGq5XNI3fX0Op1E/CtdXFep4QkSVLe\nM2GRJKnAuDW/JElSHjJhkSSp0BRhxGLCIkmS8p4JiyRJBSS3jX7xRSwmLJIkKe+ZsEiSVEiiY/dh\n6SgmLJIkKe+ZsEiSVGCKMGAxYZEkSfnPhEWSpEJThBGLAxZJkgpKeFuzJElSPjJhkSSpwHhbsyRJ\nUh4yYZEkqYAERbnm1oRFkiTlPxMWSZIKTRFGLCYskiQp75mwSJJUYNyHRZIkKQ+ZsEiSVGDch0WS\nJCkPmbBIklRgijBgccAiSVJBKdKd45wSkiRJec+ERZKkAuNtzZIkSXnIhEWSpAISeFuzJElSXjJh\nkSSpwBRhwGLCIkmS8p8JiyRJhaYIIxYTFkmSlPdMWCRJKjDuwyJJkpSHTFgkSSowxbgPiwMWSZIK\nTBGOV5wSkiRJ+c+ERZKkQlOEEYsJiyRJynsmLJIkFZDA25olSZLykgmLJEmFJIrztmYTFkmSlPdM\nWCRJKjBFGLCYsEiSpPxnwiJJUqEpwojFhEWSJOU9ExZJkgpKFOU+LA5YJEkqMN7WLEmSlIdMWCRJ\nKiBBUa65NWGRJEn5z4RFkqRCU4QRiwmLJEnKeyYskiQVmGK8rdmERZIk5T0TFkmSCoz7sEiSJOUh\nByySJBWYaKdHq84d0TsibomI1yPitYjYPSL6RsRDEfFW9m+frG5ExJ8iYnJEvBQRO7b1mh2wSJKk\ntfFH4P6U0mhgO+A14GzgkZTSKOCR7DXAIcCo7HE6cHlbT+qARZKkQhK5NSzt8VjjqSM2APYGrgRI\nKVWmlBYCRwHXZtWuBY7Onh8FXJdyngV6R8Tgtly2AxZJkgpOu00K9YuICQ0ep6924pHAHODqiHgh\nIv4vIroDA1NKs7I67wMDs+dDgGkN3j89K1tr3iUkSZLqzE0pjWnheCdgR+DbKaVxEfFHVk7/AJBS\nShGR1nXHTFgkSSogQcdNCZFLSKanlMZlr28hN4D5oG6qJ/t3dnZ8BjCswfuHZmVrzQGLJElqlZTS\n+8C0iNgiK9ofeBUYC5yalZ0K3Jk9Hwt8IbtbaDdgUYOpo7XilJAkSQWmg/eN+zbwt4joDLwDfIlc\nAHJzRJwGvAscl9W9FzgUmAwsy+q2iQMWSZLUaimlSUBT61z2b6JuAr61Ls7rgEWSpAJTjFvzO2BZ\nS6/9Z9LcnUZu8G5H90P0A+Z2dCekPOL3RH7YuKM78HHlgGUtpZT6d3QfBBExYQ233klFxe+J4hId\nvYqlA3iXkCRJynsmLJIkFZriC1hMWFSwrujoDkh5xu8JfayZsKggpZT84Sw14PdEcSnCgMUBiyRJ\nhWQtttH/WHFKSJIk5T0TFkkqYBHRM6W0OCIi21VURcDbmqUCEhHbdXQfpI6SfZjcxsCEiNgppZQi\ninGiQMXCAYsKUkTsDVzf4BNDpaKSct4FrgGujojtHbQUkWinRx5zwKKCExGjgB8DP0spvRERTm2q\nqGTpSglASunXwPXAjRGxg4MWfVw5YFEh2gToAZwYEV1SStX+gFaxqFurklKqjYg+ACmlC4G/4qCl\naBRhwOKiW+W/uh/Q2Xx9bUrpgYhYCpwAnBkRv08pVUZESUqptoO7K7WruoW1EXEmsF1ElAE/SSld\nFBHVwHUR8eWU0vgO7ai0jpmwKO9lg5UjgNuBCyLiXmAacA8wAPj/9u4/XO/5vuP481WSlMSI+HER\notaEIqNaKlquabWjGm0EQanQy4+MhqsLa9eudLMQ1W5WqVZt0nZXrH6lWC29iPjVa2iGbiumqkUQ\nkTikCYlIvPbH53O4m+uELDn3ue9zzuuR675y5/vz/b2vnHPe5/Pr/VVJA5OsRH8h6Uzg08AZwD7A\nlZL2t/1tYCYwXdKgVsYYzdW5Fkt3v9pZEpZoe5J2A84BDgFupHQJLbQ9G7gV2BbYsXURRjRXF907\nw4ATgdOBXwMPAFdIOtD2NOBQ26/1cJgRTZUuoWg7tbVkZX0/CHgJuBY4CpgIHGZ7haQxtmdLut92\nRwtDjmiqhm6gvwQGARcAo4Cxtg+u+8YDx0qaZ/ullgUbPUD9ch2WJCzRVmp//AGSNgFeA/YF5lCa\nv4cBh9teUKc1XyZpnO3ftS7iiJ4h6QhgDDC5dpN21O3jKK3lDwHfsL2ihWFGNE0Slmg3Bl4Fvgbs\nAhxle56kmcDZwOGShgCfB76cZCX6KkmDOrt1JA0HDgb2BhbWQ5ZTxqucDOwMHFfXZYk+TrT/eJNm\nSMISbaPOBlol6XfAlsB/ASOBe23/SNJSyviVYcBZtudmOfLoiyQNBk6SdCuwG7Ar8F1gB0rL4mTb\nr0j6V+AaYLDtF1oXcUTzJWGJtlGbubexvVDSvsCHgRMkDa2zH+4E5tl+pvGcFoUb0TQ1GXkSuA94\nEXhfXXfla5SZQX8vaYrt5fWUV1oUakSPySyhaClJw2tygqSxwBxJ11FaUO6kTF3eU9IMyoygoS0L\nNqJn/RZ4AlgN/End9ihwGWXhxItbFFe0gf44rTktLNFq44EJkr4BnAD8BdAB/HPtw58q6WnKInHn\n2/6fFsYa0SPqjJ/fAvsDR1DqZp1t+w5JfwRcAWT8VvQrSViipWxfJmkj4EvA/wJza9P3UcC1kgbb\n/gplnQkyZiX6iT2B84BTbV8vaTNKEj+LMvD2+IxZ6d/647TmdAlFS9UxK5cCVwGjgTGSNrb9BHAc\n8GlJuzYUekuyEn1WLT+B7a9TChp+R9K+tmcAkyldQV+w/XzrooxojbSwRI9rqA20F3C2pLtsXyVp\nU8p05r+ti1/9un6zXv4Ol4zo9SR9ADhV0mzbN9v+lqSBwE2SjrZ9i6Sf2V7d6lijxXrBeJNmSAtL\n9LiG2kCXAe8FTpZ0ou3pwL8B04AP1WOTrESf1MVy+09RamQdJOlTALYvqtv+qo7pSrIS/VZaWKLH\nSdoGOBeYZPsRSacAH5a02vbl9bfKVa2NMqJ5GsdiSZpIWW5/GWXmzznARyVtQfk6+G9gamoDRSfV\nV3+ThCV6xBqDZVdQwSO2ggAACB9JREFUWve2Bx6hjF/ZE5gs6dU6piWiz5M0CTge+DJwD6Vu1gzg\nM8BhwO7ACbafbFWMEe0iXULRI2o30EckHWn795RihgdI2tv2G8BNwGLg6Lr0fkSfI2lEnflmScOA\nA4FxlHVWbgPm2H7B9pW2jwcOtv1wK2OONqUmvdpYEpboSdsB35R0KHAH5f/fRZIuAS4Hzgc2oSxD\nHtGnSNoWmAL8uaQhtl8EFgEXAocA42y/LmmKpIMAUoU84i1JWKLpJG0naYDt6yn98xdTkpdvAZcA\nzwNHAgOAUcCzrYo1ookWAfMoXaEn10G3C4CJwOdsL5c0gdJFlCKG8bbUpD/tLGNYoqkkjaAkKQ9K\nmmn7hrqmytWU9SR+DNxef6O8CPhs1piIvkTSKOBdth+rVceXAJ8ETrN9cV175RZJ8ynFPiemCnm8\nk/44rTkJSzTbIuBxyuqcKyXNsn2dpHHAeZLm2F4MPAwcY/vpVgYb0Z3qOJXHgMWS/oZSF+j7wObA\nSEmn2z5D0mjK9+PFjcU9I+ItSViiWzUsCncAZVXOxXX5/VOA/YChkh4FDJxse7Gkd9le1Mq4I5rB\n9ouSPg7MoXTB7wVcQ5nCvBIYXbuGfmB7Resijd6mHzawZAxLdK+GReGmA3sA0ySdYvufgLuB9wPf\nBq6xfX89542WBRzRZLbnUgbVngF8gVLg805gBPDRum1Qq+KL6C3SwhLdStJ7gLOAscDBwFDKVOXB\ntv8RuEHSdrYXpJBh9Be2b5N0DvArYIztH0q6mTLQfFPbS1obYfQ6/bCJJQlLbDBJGzUsGf4qcCaw\nA/BFygJYH6OMVxlai7othBQyjP6l1gJ6A7hP0v51WnNErKMkLLHeJO0MdNheUissr6ol71+QdAQw\n0/ZTkpYAs4B/h3QBRf9le3YtPTFH0gfztRDrq92nIDdDEpbYEO+lTFfe2fbLnUlLw/7TJJmyWNYE\n279oTZgR7cP2TZJuT7IS8f+ThCXWm+05ko4DHpC0j+2XJA20vdL2T+qUTgMn2r6nxeFGtA3by1od\nQ/Reon+uw6IMI4gNJemTlFlB+3YuJS7pQGA8cEGWF4+I6D6SfgZs1aTLL7Z9aJOuvUGSsES3qEnL\nd2z/saQ9KLWCTrf9kxaHFhERfUASlug2NWmZRVl6fJLtGzN1OSIiukMSluhWkj4GbGF7VpKViIjo\nLklYoimSrERERHdKwhIRERFtL7WEIiIiou0lYYmIiIi2l4QlIiIi2l4Slog+StIPJP1dfX+gpMd6\n6L6WNLKbr/nms/TkuRHRPpKwRLSQpCclLZe0TNLC+sN1SHffx/Y9tnddh3hOkvTz7r5/w/XvlHRK\ns64fEX1XEpaI1jvc9hDgA8A+wF+veYCk1P2KiH4tCUtEm7D9LDAbGA1vdq2cKelx4PG6baykX0p6\nWdJ/SNqz83xJe0t6UNJSSdcA727Yd5CkZxr+vaOkWZIWSXpR0nRJuwHfA/avLT4v12MHSfqmpKdr\nK9D3JG3ScK1zJS2Q9Jykz6/v80u6TtLzkpZIuruWeGi0laTb6vPdJWmnhnPfV/d1SHpM0oS13GMr\nST+tn1+HpHsk5ftgRC+QL9SINiFpR+Aw4KGGzeOA/YDdJe0NXAWcDgwDrgBurgnFQOBG4F+ALYHr\ngCPXcp+NgJ8CTwHvAYYDP7b9KDAJuNf2ENtb1FOmAbsA7wdG1uPPq9c6FDgH+AQwCvj4BnwEs+s1\ntgEeBGausf944AJK0bdfdu6XNBi4Dbi6nnsscLmk3bu4xxTgGWBrYFvgK5SK4hHR5pKwRLTejbU1\n4+fAXcCFDfsust1hezlwGnCF7fttr7b9Q+A1YEx9DQAutf267euBeWu534eA7YFzbb9ie4XtLset\nSFK97xdrHEtrfMfWQyYAM2z/yvYrwNfX90OwfZXtpbZfq9fZS9LmDYfcYvvuuv+rlJagHYGxwJO2\nZ9heZfsh4Abg6C5u8zqwHbBT/ZzuyYrMEb1D+sUjWm+c7Tlr2Te/4f1OwERJkxu2DaQkHwaeXeOH\n71NrueaOwFO2V61DbFsDmwIPlNwFAAEb1ffbAw+swz3fVm31mUpJMrYG3qi7tqIU04SGz8L2Mkkd\n9f47Aft1dmFVG1Nam9Z0CSUZurU+z/dtT1ufmCOiZyVhiWhvjQnIfGCq7alrHiTpT4Hha9RwGgE8\n0cU15wMjJG3cRdKyZmvDYmA5sEcdY7OmBZQEqNOItT/K2/os8BlKl9KTwObAS5TkqNOb96kzqbYE\nnqM8z122P/FON6ktRFOAKZJGA3MlzbN9+3rGHRE9JF1CEb3HlcAkSfupGCzpU5I2A+4FVgFnSRog\naTyl66crv6AkGtPqNd4t6SN130JghzomBttv1Pv+g6RtACQNl3RIPf5a4CRJu0vaFDh/HZ5j43rP\nztcAYDNK99aLlBadC7s47zBJB9TYLgDusz2fMh5nF0mfq88+QNK+dRDxH6iDlkfWrq4lwGreas2J\niDaWhCWil7D9n8CpwHRK68NvgJPqvpXA+PrvDuAYYNZarrMaOJwygPZpyiDUY+ruucDDwPOSFtdt\nX6r3uk/S74E5wK71WrOBS+t5v6l/v5PvUlptOl8zgB9RupOeBR4B7uvivKspCVEH8EHghBrDUuDP\nKONqngOeBy4GBnVxjVE1/mWUJO9y23esQ8wR0WKp1hwRERFtLy0sERER0faSsERERETbS8ISERER\nbS8JS0RERLS9JCwRERHR9pKwRERERNtLwhIRERFtLwlLREREtL0kLBEREdH2/g/8otsK5L9ZAgAA\nAABJRU5ErkJggg==\n","text/plain":["<Figure size 576x576 with 2 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"tyy-Aox3Rnz6","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}